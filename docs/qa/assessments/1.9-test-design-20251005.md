# Test Design: Story 1.9

Date: 2025-10-05
Designer: Quinn (Test Architect)

## Test Strategy Overview

- **Total test scenarios**: 22
- **Unit tests**: 20 (90.9%)
- **Integration tests**: 2 (9.1%)
- **E2E tests**: 0 (0%)
- **Priority distribution**: P0: 18, P1: 4, P2: 0, P3: 0

### Test Level Distribution Justification

This story focuses on **error handling logic and component error states**, which are primarily unit-level concerns:

**Unit-heavy approach (90.9%)**:

- Error handler is pure logic with no external dependencies (14 unit tests)
- Header component error states are React state management (6 unit tests)
- Fast feedback for critical error path validation
- Appropriate for testing isolated error handling logic

**Minimal integration (9.1%)**:

- Health endpoint requires testing error interaction with Prisma mock (2 integration tests)
- No E2E tests needed - error handling is not user-facing workflow

### Priority Distribution Analysis

**P0 (Critical) - 18 tests (81.8%)**:

- All error handler tests are security-critical (prevent information leakage)
- Environment-specific behavior is compliance-critical
- Error path coverage directly impacts system reliability

**P1 (High) - 4 tests (18.2%)**:

- Header component error states affect user experience
- Health endpoint error paths affect monitoring

**No P2/P3 tests**: All scenarios are critical for security and reliability

## Test Scenarios by Acceptance Criteria

### AC1: Error handler coverage 27.77% → 95%+

**Target**: Comprehensive error type handling and environment-specific behavior

#### Scenarios (14 tests - All P0)

| ID           | Level | Priority | Test                                    | Justification                          | Mitigates Risk |
| ------------ | ----- | -------- | --------------------------------------- | -------------------------------------- | -------------- |
| 1.9-UNIT-001 | Unit  | P0       | P2002 unique constraint → 400           | Pure error classification logic        | TECH-001       |
| 1.9-UNIT-002 | Unit  | P0       | P2025 record not found → 404            | Pure error classification logic        | TECH-001       |
| 1.9-UNIT-003 | Unit  | P0       | Unknown Prisma code → 500               | Error fallback logic                   | SEC-002        |
| 1.9-UNIT-004 | Unit  | P0       | ZodError → 400 VALIDATION_ERROR         | Validation error detection             | TECH-001       |
| 1.9-UNIT-005 | Unit  | P0       | NotFoundError → 404 NOT_FOUND           | Custom error class mapping             | -              |
| 1.9-UNIT-006 | Unit  | P0       | ValidationError → 400 VALIDATION_ERROR  | Custom error class mapping             | -              |
| 1.9-UNIT-007 | Unit  | P0       | UnauthorizedError → 401 UNAUTHORIZED    | Security-critical error classification | -              |
| 1.9-UNIT-008 | Unit  | P0       | ForbiddenError → 403 FORBIDDEN          | Security-critical error classification | -              |
| 1.9-UNIT-009 | Unit  | P0       | Custom error with statusCode/code props | Extensibility and future error types   | -              |
| 1.9-UNIT-010 | Unit  | P0       | Development env → actual error message  | Security-critical information control  | SEC-001        |
| 1.9-UNIT-011 | Unit  | P0       | Production env → generic error message  | Security-critical information control  | SEC-001        |
| 1.9-UNIT-012 | Unit  | P0       | Development env → log with stack trace  | Security-critical logging control      | SEC-001        |
| 1.9-UNIT-013 | Unit  | P0       | Production env → log without stack      | Security-critical logging control      | SEC-001        |
| 1.9-UNIT-014 | Unit  | P0       | Non-Error object → 500 generic message  | Error fallback and type safety         | SEC-002        |

**Coverage Requirements**:

- All Prisma error codes (P2002, P2025, unknown)
- All custom error classes (NotFoundError, ValidationError, UnauthorizedError, ForbiddenError)
- ZodError validation failures
- Environment-specific behavior (development vs production)
- Non-Error object edge case
- Console error logging verification

**Test Implementation Notes**:

- Create `createPrismaError(code, message)` helper with clientVersion: '5.22.0'
- Create `createZodError(message)` helper with name property set to 'ZodError'
- Use `vi.stubEnv('NODE_ENV', 'production|development')` for environment tests
- Use `afterEach(() => vi.unstubAllEnvs())` for cleanup (prevent test leakage)
- Mock `console.error` to prevent test output pollution and verify logging
- Verify response structure: { error, message, timestamp }

---

### AC2 & AC3: Health endpoint error path + coverage 68.96% → 100%

**Target**: Database failure scenarios and error handling

#### Scenarios (2 tests - All P1)

| ID          | Level       | Priority | Test                                         | Justification                  | Mitigates Risk |
| ----------- | ----------- | -------- | -------------------------------------------- | ------------------------------ | -------------- |
| 1.9-INT-001 | Integration | P1       | Database query fails → 503 unhealthy         | Tests Prisma error interaction | -              |
| 1.9-INT-002 | Integration | P1       | Non-Error object thrown → 503 with "Unknown" | Error type safety and fallback | SEC-002        |

**Coverage Requirements**:

- Lines 19-28 (error handling block) currently uncovered
- Both error paths: Error object and non-Error object
- Response structure: { status: 'unhealthy', timestamp, error }
- HTTP status 503 SERVICE_UNAVAILABLE

**Test Implementation Notes**:

- Mock `prisma.$queryRaw` to reject with errors
- Verify error response format matches success format structure
- Test both Error object and string/unknown error types

**Why Integration Level**:

- Tests interaction between route handler and Prisma client mock
- Validates error handling across component boundary
- Database dependency (even mocked) crosses component boundary

---

### AC4 & AC5: Header component error handling + coverage 66.66% → 100%

**Target**: Network failure scenarios and loading state management

#### Scenarios (6 tests - All P1)

| ID           | Level | Priority | Test                                    | Justification                       | Mitigates Risk |
| ------------ | ----- | -------- | --------------------------------------- | ----------------------------------- | -------------- |
| 1.9-UNIT-015 | Unit  | P1       | Fetch network error → console.error     | Error logging verification          | -              |
| 1.9-UNIT-016 | Unit  | P1       | Fetch non-ok response → console.error   | Error logging verification          | -              |
| 1.9-UNIT-017 | Unit  | P1       | Finally block resets isLoggingOut state | State cleanup after error           | TECH-003       |
| 1.9-UNIT-018 | Unit  | P1       | Error path → router.push NOT called     | No redirect on error (stay on page) | -              |
| 1.9-UNIT-019 | Unit  | P1       | Button disabled during logout           | Loading state management            | TECH-003       |
| 1.9-UNIT-020 | Unit  | P1       | Button enabled after error              | State reset after error             | TECH-003       |

**Coverage Requirements**:

- catch block (error handling)
- finally block (state cleanup)
- Error scenarios: network failure, non-ok response
- Loading state transitions: false → true → false

**Test Implementation Notes**:

- Create `Header.test.tsx` in `components/layout/`
- Setup Chakra UI wrapper: `<ChakraProvider>{children}</ChakraProvider>`
- Mock Next.js `useRouter` with `mockPush` function
- Mock `global.fetch` to simulate errors and non-ok responses
- Use `waitFor()` for async state assertions (prevent flakiness)
- Mock `console.error` to verify error logging
- Use `fireEvent.click` for button interaction
- Test loading state with `screen.getByText(/logging out/i)`

**Why Unit Level**:

- Tests React component state management (isolated logic)
- No real API calls (fetch is mocked)
- No multi-component interaction
- Focus on component error state behavior

**Async Testing Strategy**:

- All assertions use `waitFor()` to handle React state updates
- Mock fetch before rendering component
- Test state transitions in sequence
- Verify loading states appear and disappear correctly

---

### AC6-11: Specific error type validations

**Coverage**: Integrated into scenarios above

- AC6 (Prisma error codes): 1.9-UNIT-001, 1.9-UNIT-002, 1.9-UNIT-003
- AC7 (Custom error classes): 1.9-UNIT-005, 1.9-UNIT-006, 1.9-UNIT-007, 1.9-UNIT-008
- AC8 (Environment-specific messaging): 1.9-UNIT-010, 1.9-UNIT-011
- AC9 (ZodError handling): 1.9-UNIT-004
- AC10 (Console error logging): 1.9-UNIT-012, 1.9-UNIT-013
- AC11 (All tests pass): Validation in Task 10

---

### AC12: Overall project coverage 58.93% → 95%+

**Target**: Comprehensive test coverage across entire project

#### Validation (No new scenarios - verification only)

**Coverage Targets**:

- lib/api/errorHandler.ts: 27.77% → 95%+ (14 tests)
- app/api/health/route.ts: 68.96% → 100% (2 tests)
- components/layout/Header.tsx: 66.66% → 100% (6 tests)
- Overall project: 58.93% → 95%+

**Verification Command**:

```bash
pnpm test:coverage
```

**Expected Results**:

```
File                          | % Stmts | % Branch | % Funcs | % Lines
------------------------------ | ------- | -------- | ------- | -------
lib/api/errorHandler.ts       | 95%+    | 95%+     | 100%    | 95%+
app/api/health/route.ts       | 100%    | 100%     | 100%    | 100%
components/layout/Header.tsx  | 100%    | 100%     | 100%    | 100%
------------------------------ | ------- | -------- | ------- | -------
Overall Coverage              | 95%+    | 90%+     | 95%+    | 95%+
```

**Review Process**:

1. Run coverage command
2. Open `coverage/index.html` in browser
3. Review each file for missed branches
4. Document any intentionally uncovered lines
5. Verify all error paths are green (covered)

---

## Risk Coverage

### Risk-to-Test Mapping

| Risk ID  | Score | Tests Mitigating Risk                                  | Coverage Level |
| -------- | ----- | ------------------------------------------------------ | -------------- |
| SEC-001  | 9     | 1.9-UNIT-010, 1.9-UNIT-011, 1.9-UNIT-012, 1.9-UNIT-013 | Complete       |
| TECH-001 | 6     | 1.9-UNIT-001, 1.9-UNIT-002, 1.9-UNIT-004               | Complete       |
| OPS-001  | 6     | 1.9-UNIT-015 through 1.9-UNIT-020                      | Complete       |
| TECH-002 | 4     | All tests with environment stubbing                    | Complete       |
| SEC-002  | 2     | 1.9-UNIT-003, 1.9-UNIT-014, 1.9-INT-002                | Complete       |
| TECH-003 | 2     | 1.9-UNIT-017, 1.9-UNIT-019, 1.9-UNIT-020               | Complete       |
| OPS-002  | 2     | All 22 tests contribute to coverage target             | Complete       |
| PERF-001 | 1     | N/A (accepted risk)                                    | N/A            |

### Critical Risk Mitigation (SEC-001)

**Risk**: Production error message information leakage
**Score**: 9 (Critical)
**Mitigation Strategy**: 4 dedicated test scenarios

**Test Coverage**:

1. **1.9-UNIT-010**: Development environment returns actual error messages
   - Verifies detailed errors available for debugging
   - Ensures developers can diagnose issues

2. **1.9-UNIT-011**: Production environment returns generic messages
   - Prevents stack trace leakage
   - Prevents database structure exposure
   - Validates "An unexpected error occurred." message

3. **1.9-UNIT-012**: Development logging includes stack traces
   - Verifies complete error context in logs
   - Ensures debugging information available

4. **1.9-UNIT-013**: Production logging excludes stack traces
   - Prevents log-based information disclosure
   - Validates secure logging in production

**Success Criteria**:

- All 4 tests pass
- Manual security review confirms no information leakage
- Staging environment testing with production NODE_ENV configuration

### High Risk Mitigation (TECH-001, OPS-001)

**TECH-001: Test Helper Accuracy**

- **Tests**: 1.9-UNIT-001, 1.9-UNIT-002, 1.9-UNIT-004
- **Validation**: Helpers match actual error structures
- **Success**: Prisma clientVersion matches package.json (5.22.0)

**OPS-001: Test Flakiness**

- **Tests**: 1.9-UNIT-015 through 1.9-UNIT-020
- **Validation**: All tests use waitFor() for async assertions
- **Success**: 10 consecutive successful runs without failures

---

## Test Implementation Plan

### Phase 1: Error Handler Unit Tests (14 tests)

**File**: `lib/api/errorHandler.test.ts` (NEW)

**Setup**:

```typescript
import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
import { Prisma } from '@prisma/client';
import { handleApiError } from './errorHandler';

// Helper: Create Prisma errors
function createPrismaError(code: string, message: string) {
  return new Prisma.PrismaClientKnownRequestError(message, {
    code,
    clientVersion: '5.22.0', // MUST match package.json
  });
}

// Helper: Create ZodError
function createZodError(message: string) {
  const error = new Error(message);
  error.name = 'ZodError'; // Detection uses name, not instanceof
  return error;
}

// Mock console.error
const mockConsoleError = vi.spyOn(console, 'error').mockImplementation(() => {});

describe('Error Handler', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  afterEach(() => {
    vi.unstubAllEnvs(); // CRITICAL: Prevent environment leakage
  });

  // Test implementations...
});
```

**Test Groups**:

1. Prisma Errors (3 tests): 1.9-UNIT-001, 1.9-UNIT-002, 1.9-UNIT-003
2. Validation Errors (1 test): 1.9-UNIT-004
3. Custom Error Classes (5 tests): 1.9-UNIT-005 through 1.9-UNIT-009
4. Environment-Specific (4 tests): 1.9-UNIT-010 through 1.9-UNIT-013
5. Edge Cases (1 test): 1.9-UNIT-014

**Execution Priority**: P0 (all 14 tests)

---

### Phase 2: Health Endpoint Integration Tests (2 tests)

**File**: `app/api/health/route.test.ts` (MODIFY)

**Setup**:

```typescript
import { describe, it, expect, vi } from 'vitest';
import { GET } from './route';
import { prisma } from '@/lib/db/client';

vi.mock('@/lib/db/client', () => ({
  prisma: {
    $queryRaw: vi.fn(),
  },
}));

describe('Health Endpoint Error Paths', () => {
  // Existing tests remain...

  // New error path tests
  it('should return 503 when database query fails (1.9-INT-001)', async () => {
    vi.mocked(prisma.$queryRaw).mockRejectedValueOnce(new Error('Connection refused'));

    const response = await GET();
    const data = await response.json();

    expect(response.status).toBe(503);
    expect(data.status).toBe('unhealthy');
    expect(data.error).toBe('Connection refused');
  });

  it('should handle non-Error objects (1.9-INT-002)', async () => {
    vi.mocked(prisma.$queryRaw).mockRejectedValueOnce('String error');

    const response = await GET();
    const data = await response.json();

    expect(response.status).toBe(503);
    expect(data.error).toBe('Unknown error');
  });
});
```

**Test Groups**:

1. Database Failure (1 test): 1.9-INT-001
2. Non-Error Object (1 test): 1.9-INT-002

**Execution Priority**: P1

---

### Phase 3: Header Component Unit Tests (6 tests)

**File**: `components/layout/Header.test.tsx` (NEW)

**Setup**:

```typescript
import React from 'react';
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { describe, it, expect, vi, beforeEach } from 'vitest';
import { ChakraProvider } from '@chakra-ui/react';
import { Header } from './Header';

// Mock Next.js router
const mockPush = vi.fn();
vi.mock('next/navigation', () => ({
  useRouter: () => ({
    push: mockPush,
  }),
}));

// Chakra UI wrapper
function Wrapper({ children }: { children: React.ReactNode }): JSX.Element {
  return <ChakraProvider>{children}</ChakraProvider>;
}

// Mock console.error
const mockConsoleError = vi.spyOn(console, 'error').mockImplementation(() => {});

describe('Header Component Error Handling', () => {
  beforeEach(() => {
    vi.clearAllMocks();
  });

  // Test implementations...
});
```

**Test Groups**:

1. Error Logging (2 tests): 1.9-UNIT-015, 1.9-UNIT-016
2. State Management (2 tests): 1.9-UNIT-017, 1.9-UNIT-018
3. Loading States (2 tests): 1.9-UNIT-019, 1.9-UNIT-020

**Key Patterns**:

- Use `waitFor()` for all async assertions
- Mock `global.fetch` before rendering
- Test state transitions sequentially
- Verify button text changes

**Execution Priority**: P1

---

### Phase 4: Coverage Validation

**File**: Coverage report analysis

**Process**:

1. Run `pnpm test:coverage`
2. Verify all 22 tests pass
3. Check coverage percentages:
   - Error handler: ≥95%
   - Health endpoint: 100%
   - Header component: 100%
   - Overall: ≥95%
4. Open `coverage/index.html`
5. Review each file for uncovered lines
6. Document any intentional gaps

**Success Criteria**:

- All targets met
- No uncovered error paths
- HTML report shows green coverage

---

## Test Execution Strategy

### Recommended Execution Order

**Priority**: Fast feedback → Critical paths → Complete coverage

1. **P0 Unit Tests** (14 tests, ~5 seconds)
   - Error handler Prisma errors (3 tests)
   - Error handler validation errors (1 test)
   - Error handler custom classes (5 tests)
   - Error handler environment-specific (4 tests)
   - Error handler edge cases (1 test)
   - **Rationale**: Fail fast on security-critical error handling

2. **P1 Integration Tests** (2 tests, ~2 seconds)
   - Health endpoint database failure (1 test)
   - Health endpoint non-Error object (1 test)
   - **Rationale**: Validate component interaction quickly

3. **P1 Component Tests** (6 tests, ~3 seconds)
   - Header error logging (2 tests)
   - Header state management (2 tests)
   - Header loading states (2 tests)
   - **Rationale**: Complete functional validation

4. **Coverage Validation** (~5 seconds)
   - Run full coverage report
   - Verify all targets achieved
   - **Rationale**: Confirm comprehensive coverage

**Total Estimated Time**: <15 seconds for all 22 tests

---

## Test Quality Checklist

### Pre-Implementation Review

- [x] Every AC has test coverage
- [x] Test levels are appropriate (not over-testing)
- [x] No duplicate coverage across levels
- [x] Priorities align with business risk
- [x] Test IDs follow naming convention ({EPIC}.{STORY}-{LEVEL}-{SEQ})
- [x] Scenarios are atomic and independent

### Implementation Checklist

- [ ] Test helpers match actual error structures
  - [ ] Prisma clientVersion matches package.json (5.22.0)
  - [ ] ZodError name property set correctly
- [ ] Environment stubbing uses afterEach cleanup
- [ ] Console.error mocking prevents output pollution
- [ ] React tests use waitFor() for async assertions
- [ ] All 22 tests pass independently
- [ ] Tests pass 10 consecutive runs (no flakiness)

### Post-Implementation Validation

- [ ] Coverage targets achieved (95%+ overall)
- [ ] HTML coverage report reviewed
- [ ] No uncovered error paths
- [ ] Security review completed (environment-specific tests)
- [ ] CI pipeline runs successfully

---

## Test Maintenance Considerations

### Long-term Maintenance

**Test Stability**:

- Environment cleanup prevents test order dependencies
- waitFor() prevents React timing issues
- Mocked dependencies isolate from external changes
- Helper functions centralize error construction logic

**Test Evolution**:

- Add new error types to error handler test suite
- Extend coverage when new error paths added
- Update helpers when Prisma version changes
- Review environment behavior when deployment config changes

**Test Performance**:

- Unit tests execute in <10 seconds (acceptable)
- Console mocking adds negligible overhead
- Coverage collection adds ~5 seconds (acceptable)

### Maintenance Triggers

**Review tests when**:

- Prisma client version upgraded (update helpers)
- New error types added to error handler
- Environment configuration changes
- React Testing Library upgraded (review async patterns)
- Coverage drops below 95% (investigate and restore)

---

## Integration with Quality Gates

### Test Design Gate Criteria

**PASS Criteria**:

- All 22 test scenarios documented
- Coverage plan addresses all ACs
- Risk mitigation mapped to tests
- Execution strategy defined

**CONCERNS Criteria**:

- Coverage gaps identified but have mitigation plan
- Some tests at inappropriate level (with justification)

**FAIL Criteria**:

- ACs without test coverage
- Duplicate coverage without justification
- No risk mitigation strategy

**Current Status**: PASS

- All ACs covered by test scenarios
- Risk mitigation comprehensive
- Test level decisions justified
- Execution strategy defined

---

## Summary and Recommendations

### Test Strategy Strengths

1. **Comprehensive Coverage**: 22 scenarios cover all error paths
2. **Appropriate Test Levels**: 90.9% unit tests for logic validation
3. **Risk-Focused**: 81.8% P0 tests for critical security paths
4. **Fast Feedback**: <15 seconds total execution time
5. **Maintainable**: Clear patterns and helper functions

### Critical Success Factors

1. **Test Helper Accuracy**: Prisma/ZodError helpers must match reality
2. **Environment Cleanup**: vi.unstubAllEnvs() prevents test leakage
3. **Async Handling**: waitFor() prevents React test flakiness
4. **Security Validation**: Environment-specific tests are critical
5. **Coverage Verification**: HTML report review catches gaps

### Recommendations

1. **Implement P0 tests first** (14 error handler tests)
   - Security-critical error handling
   - Environment-specific behavior
   - Fast feedback on critical paths

2. **Validate test helpers early** (first test of each error type)
   - Prisma clientVersion must match package.json
   - ZodError name property detection logic

3. **Use established patterns consistently**
   - afterEach cleanup for environment stubs
   - waitFor() for all async assertions
   - Mock console.error to prevent output pollution

4. **Monitor test stability**
   - Run tests 10 times consecutively
   - Check for flakiness in CI
   - Investigate any timing-related failures

5. **Complete security review**
   - Verify environment-specific tests pass
   - Manual staging environment validation
   - Confirm no information leakage in production

### Expected Outcomes

**After Implementation**:

- ✅ 22 new tests passing (100% success rate)
- ✅ Error handler coverage: 27.77% → 95%+
- ✅ Health endpoint coverage: 68.96% → 100%
- ✅ Header component coverage: 66.66% → 100%
- ✅ Overall project coverage: 58.93% → 95%+
- ✅ All critical risks mitigated
- ✅ Security validation complete

**Test Suite Metrics**:

- Total tests: 90 (68 existing + 22 new)
- Execution time: <30 seconds (15s for new tests)
- Flakiness rate: 0% (target)
- Coverage: ≥95% (target)

**Quality Gate Status**: PASS (after implementation and security review)

---

## References

- **Risk Profile**: `/home/sallvain/dev/personal/Open-Sci-Ed-Lesson-Repository/docs/qa/assessments/1.9-risk-20251005.md`
- **Story**: `/home/sallvain/dev/personal/Open-Sci-Ed-Lesson-Repository/docs/stories/1.9.story.md`
- **Test Levels Framework**: `.bmad-core/data/test-levels-framework.md`
- **Test Priorities Matrix**: `.bmad-core/data/test-priorities-matrix.md`
